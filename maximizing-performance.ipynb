{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "images = np.load(\"D:/work/JHUschoolStuff/machinelearning/project1/cs475_project_data/images.npy\")\n",
    "labels = np.load(\"D:/work/JHUschoolStuff/machinelearning/project1/cs475_project_data/labels.npy\")\n",
    "test = np.load(\"D:/work/JHUschoolStuff/machinelearning/project1/cs475_project_data/test_images.npy\")\n",
    "height = images.shape[1]\n",
    "width = images.shape[2]\n",
    "size = height * width\n",
    "images = (images - images.mean()) / images.std()\n",
    "data = images.reshape(images.shape[0],size)\n",
    "data = torch.from_numpy(data).float().cuda()\n",
    "labels = torch.from_numpy(labels).float().cuda()\n",
    "test_data = test.reshape(test.shape[0], size)\n",
    "test_data = (test_data - test_data.mean()) / test_data.std()\n",
    "batch_size = 1\n",
    "NUM_OPT_STEPS = 5000\n",
    "train_seqs, train_labels = data[0:45000,:], labels[0:45000]\n",
    "val_seqs, val_labels = data[45000:,:], labels[45000:]\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "class TooSimpleConvNN(torch.nn.Module):\n",
    "    def __init__(self, chan_1, chan_2, chan_3):\n",
    "        super().__init__()\n",
    "        # 3x3 convolution that takes in an image with one channel\n",
    "        # and outputs an image with 8 channels.\n",
    "        self.conv1 = torch.nn.Conv2d(1, chan_1, kernel_size=3)\n",
    "        # 3x3 convolution that takes in an image with 8 channels\n",
    "        # and outputs an image with 16 channels. The output image\n",
    "        # has approximately half the height and half the width\n",
    "        # because of the stride of 2.\n",
    "        self.conv2 = torch.nn.Conv2d(chan_1, chan_2, kernel_size=3, stride=1)\n",
    "        self.conv3 = torch.nn.Conv2d(chan_2, chan_3, kernel_size=3, stride=1)\n",
    "        # 1x1 convolution that takes in an image with 16 channels and\n",
    "        # produces an image with 5 channels. Here, the 5 channels\n",
    "        # will correspond to class scores.\n",
    "        self.final_conv = torch.nn.Conv2d(chan_3, 5, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        # Convolutions work with images of shape\n",
    "        # [batch_size, num_channels, height, width]\n",
    "        x = x.view(-1, height, width).unsqueeze(1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        n, c, h, w = x.size()\n",
    "        x = F.avg_pool2d(x, kernel_size=[h, w])\n",
    "        x = self.final_conv(x).view(-1, NUM_CLASSES)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TooSimpleConvNN(torch.nn.Module):\n",
    "    def __init__(self, chan_1, chan_2):\n",
    "        super().__init__()\n",
    "        # 3x3 convolution that takes in an image with one channel\n",
    "        # and outputs an image with 8 channels.\n",
    "        self.conv1 = torch.nn.Conv2d(1, chan_1, kernel_size=1)\n",
    "        # 3x3 convolution that takes in an image with 8 channels\n",
    "        # and outputs an image with 16 channels. The output image\n",
    "        # has approximately half the height and half the width\n",
    "        # because of the stride of 2.\n",
    "        self.conv2 = torch.nn.Conv2d(chan_1, chan_2, kernel_size=1, stride=1)\n",
    "        # 1x1 convolution that takes in an image with 16 channels and\n",
    "        # produces an image with 5 channels. Here, the 5 channels\n",
    "        # will correspond to class scores.\n",
    "        self.final_conv = torch.nn.Conv2d(chan_2, 5, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        # Convolutions work with images of shape\n",
    "        # [batch_size, num_channels, height, width]\n",
    "        x = x.view(-1, height, width).unsqueeze(1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        n, c, h, w = x.size()\n",
    "        x = F.avg_pool2d(x, kernel_size=[h, w])\n",
    "        x = self.final_conv(x).view(-1, NUM_CLASSES)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model = TooSimpleConvNN(16, 32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, batch_size):\n",
    "#def train(batch_size):\n",
    "    # model.train() puts our model in train mode, which can require different\n",
    "    # behavior than eval mode (for example in the case of dropout).\n",
    "    model.train()\n",
    "    # i is is a 1-D array with shape [batch_size]\n",
    "    i = np.random.choice(train_seqs.shape[0], size=batch_size, replace=False)\n",
    "    i = torch.from_numpy(i).long().cuda()\n",
    "    x = autograd.Variable(train_seqs[i, :])\n",
    "    y = autograd.Variable(train_labels[i]).long()\n",
    "    optimizer.zero_grad()\n",
    "    y_hat_ = model(x)\n",
    "    loss = F.cross_entropy(y_hat_, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    return (y == y_hat).astype(np.float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approx_train_accuracy(model):\n",
    "    i = np.random.choice(train_seqs.shape[0], size=1000, replace=False)\n",
    "    i = torch.from_numpy(i).long().cuda()\n",
    "    x = autograd.Variable(train_seqs[i, :])\n",
    "    y = autograd.Variable(train_labels[i]).long()\n",
    "    y_hat_ = model(x)\n",
    "    pred = []\n",
    "    for j in range(y_hat_.size()[0]):\n",
    "        logits = y_hat_[j,:].cpu().data.numpy()\n",
    "        pred.append(np.argmax(logits))\n",
    "    return accuracy(pred, y.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val_accuracy(model):\n",
    "    x = autograd.Variable(val_seqs)\n",
    "    y = autograd.Variable(val_labels)\n",
    "    y_hat_ = model(x)\n",
    "    pred = []\n",
    "    for j in range(y_hat_.size()[0]):\n",
    "        logits = y_hat_[j,:].cpu().data.numpy()\n",
    "        pred.append(np.argmax(logits))\n",
    "    return accuracy(pred, y.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_accuracies(tr, v):\n",
    "    ind = list(range(len(tr)))\n",
    "    plt.plot(ind,tr,'-ro')\n",
    "    plt.title('Training accuracy as a function of iteration')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('training accuracy')\n",
    "    plt.show()\n",
    "    plt.plot(ind,v,'-go')\n",
    "    plt.title('Validation accuracy as a function of iteration')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('validation accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def tune_hyperparameters(layer_1, layer_2, layer_3, batch, rate, step):\n",
    "    best_avg = 0\n",
    "    l_1, l_2, l_3, bat, rat, stp = 0, 0, 0, 0, 0, 0\n",
    "    for i in layer_1:\n",
    "        for j in layer_2:\n",
    "            for r in layer_3:\n",
    "                for k in batch:\n",
    "                    for l in rate:\n",
    "                        for m in step:\n",
    "                            train_accs, val_accs = [], []\n",
    "                            model = TooSimpleConvNN(i, j, r)\n",
    "                            model.cuda()\n",
    "                            optimizer = torch.optim.Adam(model.parameters(), lr=l)\n",
    "                            for n in range(m):\n",
    "                                train(model, optimizer, k)\n",
    "                                if n % 100 == 0:\n",
    "                                    train_accs.append(approx_train_accuracy(model))\n",
    "                                    val_accs.append(val_accuracy(model))\n",
    "                            avg = np.mean(val_accs)\n",
    "                            print(avg ,\" \", k)\n",
    "                            if avg > best_avg:\n",
    "                                best_avg = avg\n",
    "                                l_1, l_2, l_3, bat, rat, stp = i, j, r, k, l, m\n",
    "                            #for s in model.children():\n",
    "                              #  s.reset_parameters()\n",
    "    \n",
    "    return l_1, l_2, l_3, bat, rat, stp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tune_hyperparameters(layer_1, layer_2, batch, rate, step):\n",
    "    best_avg = 0\n",
    "    l_1, l_2, l_3, bat, rat, stp = 0, 0, 0, 0, 0, 0\n",
    "    for i in layer_1:\n",
    "        for j in layer_2:\n",
    "            for k in batch:\n",
    "                for l in rate:\n",
    "                    for m in step:\n",
    "                        train_accs, val_accs = [], []\n",
    "                        model = TooSimpleConvNN(i, j)\n",
    "                        model.cuda()\n",
    "                        optimizer = torch.optim.Adam(model.parameters(), lr=l)\n",
    "                        for n in range(m):\n",
    "                            train(model, optimizer, k)\n",
    "                            if n % 100 == 0:\n",
    "                                train_accs.append(approx_train_accuracy(model))\n",
    "                                val_accs.append(val_accuracy(model))\n",
    "                        avg = np.mean(val_accs)\n",
    "                        print(avg ,\" \", k)\n",
    "                        if avg > best_avg:\n",
    "                            best_avg = avg\n",
    "                            l_1, l_2, bat, rat, stp = i, j, k, l, m\n",
    "                            #for s in model.children():\n",
    "                              #  s.reset_parameters()\n",
    "    \n",
    "    return l_1, l_2, bat, rat, stp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "layer_1 = [32]\n",
    "layer_2 = [32]\n",
    "layer_3 = [8]\n",
    "batch = [1024]\n",
    "rate = [0.001]\n",
    "step = [5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_1 = [1]\n",
    "layer_2 = [1]\n",
    "batch = [1]\n",
    "rate = [0.001]\n",
    "step = [10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuned = tune_hyperparameters(layer_1, layer_2, layer_3, batch, rate, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned = tune_hyperparameters(layer_1, layer_2, batch, rate, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model = TooSimpleConvNN(tuned[0], tuned[1], tuned[2])\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=tuned[4])                  \n",
    "train_accs, val_accs = [], []\n",
    "for i in range(tuned[5]):\n",
    "    train(model, optimizer, tuned[3])\n",
    "    if i % 100 == 0:\n",
    "        train_accs.append(approx_train_accuracy(model))\n",
    "        val_accs.append(val_accuracy(model))\n",
    "        print(\"%6d %5.2f %5.2f\" % (i, train_accs[-1], val_accs[-1]))\n",
    "print(np.mean(val_accs))\n",
    "plot_accuracies(train_accs, val_accs)\n",
    "print(tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TooSimpleConvNN(tuned[0], tuned[1])\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=tuned[3])                  \n",
    "train_accs, val_accs = [], []\n",
    "for i in range(tuned[4]):\n",
    "    train(model, optimizer, tuned[2])\n",
    "    if i % 100 == 0:\n",
    "        train_accs.append(approx_train_accuracy(model))\n",
    "        val_accs.append(val_accuracy(model))\n",
    "        print(\"%6d %5.2f %5.2f\" % (i, train_accs[-1], val_accs[-1]))\n",
    "print(np.mean(val_accs))\n",
    "plot_accuracies(train_accs, val_accs)\n",
    "print(tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(32, 64, 128, 0.001, 5000) 70 to 80\n",
    "(32, 16, 8, 512, 0.001, 5000) 86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_accs, val_accs = [], []\n",
    "for i in range(NUM_OPT_STEPS):\n",
    "    train(batch_size)\n",
    "    if i % 100 == 0:\n",
    "        train_accs.append(approx_train_accuracy(model))\n",
    "        val_accs.append(val_accuracy(model))\n",
    "        print(\"%6d %5.2f %5.2f\" % (i, train_accs[-1], val_accs[-1]))\n",
    "print(np.mean(val_accs))\n",
    "plot_accuracies(train_accs, val_accs)\n",
    "print(tuned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
