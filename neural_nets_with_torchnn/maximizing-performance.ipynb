{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "\n",
    "images = np.load(\"D:/work/JHUschoolStuff/machinelearning/project1/cs475_project_data/images.npy\")\n",
    "labels = np.load(\"D:/work/JHUschoolStuff/machinelearning/project1/cs475_project_data/labels.npy\")\n",
    "test = np.load(\"D:/work/JHUschoolStuff/machinelearning/project1/cs475_project_data/part_2_test_images.npy\")\n",
    "height = images.shape[1]\n",
    "width = images.shape[2]\n",
    "size = height * width\n",
    "images = (images - images.mean()) / images.std()\n",
    "data = images.reshape(images.shape[0],size)\n",
    "data = torch.from_numpy(data).float().cuda()\n",
    "labels = torch.from_numpy(labels).float().cuda()\n",
    "test_data = test.reshape(test.shape[0], size)\n",
    "test_data = (test_data - test_data.mean()) / test_data.std()\n",
    "test_data = torch.from_numpy(test_data).float().cuda()\n",
    "batch_size = 1\n",
    "NUM_OPT_STEPS = 5000\n",
    "train_seqs = data[0:45000,:]\n",
    "train_labels = labels[0:45000]\n",
    "val_seqs = data[45000:,:]\n",
    "val_labels = labels[45000:]\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TooSimpleConvNN(torch.nn.Module):\n",
    "    def __init__(self, chan_1, chan_2, chan_3, chan_4):\n",
    "        super().__init__()\n",
    "        # 3x3 convolution that takes in an image with one channel\n",
    "        # and outputs an image with 8 channels.\n",
    "        self.conv1 = torch.nn.Conv2d(1, chan_1, kernel_size=3)\n",
    "        # 3x3 convolution that takes in an image with 8 channels\n",
    "        # and outputs an image with 16 channels. The output image\n",
    "        # has approximately half the height and half the width\n",
    "        # because of the stride of 2.\n",
    "        self.conv2 = torch.nn.Conv2d(chan_1, chan_2, kernel_size=3, stride=1)\n",
    "        self.conv3 = torch.nn.Conv2d(chan_2, chan_3, kernel_size=3, stride=1)\n",
    "        self.conv4 = torch.nn.Conv2d(chan_3, chan_4, kernel_size=3, stride=1)\n",
    "        # 1x1 convolution that takes in an image with 16 channels and\n",
    "        # produces an image with 5 channels. Here, the 5 channels\n",
    "        # will correspond to class scores.\n",
    "        self.final_conv = torch.nn.Conv2d(chan_4, 5, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        # Convolutions work with images of shape\n",
    "        # [batch_size, num_channels, height, width]\n",
    "        x = x.view(-1, height, width).unsqueeze(1)\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride=1)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride=1)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride=1)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        #x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        n, c, h, w = x.size()\n",
    "        x = F.avg_pool2d(x, kernel_size=[h, w])\n",
    "        x = self.final_conv(x).view(-1, NUM_CLASSES)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, batch_size):\n",
    "#def train(batch_size):\n",
    "    # model.train() puts our model in train mode, which can require different\n",
    "    # behavior than eval mode (for example in the case of dropout).\n",
    "    model.train()\n",
    "    # i is is a 1-D array with shape [batch_size]\n",
    "    i = np.random.choice(train_seqs.shape[0], size=batch_size, replace=False)\n",
    "    i = torch.from_numpy(i).long().cuda()\n",
    "    x = autograd.Variable(train_seqs[i, :])\n",
    "    y = autograd.Variable(train_labels[i]).long()\n",
    "    i.cpu()\n",
    "    optimizer.zero_grad()\n",
    "    y_hat_ = model(x)\n",
    "    loss = F.cross_entropy(y_hat_, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approx_train_accuracy(model):\n",
    "    i = np.random.choice(train_seqs.shape[0], size=1000, replace=False)\n",
    "    i = torch.from_numpy(i).long().cuda()\n",
    "    x = autograd.Variable(train_seqs[i, :])\n",
    "    y = autograd.Variable(train_labels[i]).long()\n",
    "    y_hat_ = model(x)\n",
    "    pred = []\n",
    "    for j in range(y_hat_.size()[0]):\n",
    "        logits = y_hat_[j,:].cpu().data.numpy()\n",
    "        pred.append(np.argmax(logits))\n",
    "    return accuracy(pred, y.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val_accuracy(model):\n",
    "    x = autograd.Variable(val_seqs)\n",
    "    y = autograd.Variable(val_labels)\n",
    "    y_hat_ = model(x)\n",
    "    pred = []\n",
    "    for j in range(y_hat_.size()[0]):\n",
    "        logits = y_hat_[j,:].cpu().data.numpy()\n",
    "        pred.append(np.argmax(logits))\n",
    "    return accuracy(pred, y.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    return (y == y_hat).astype(np.float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(train_accs, val_accs):\n",
    "    plt.figure(200)\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(train_accs, 'b')\n",
    "    plt.show()\n",
    "    plt.figure(300)\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Accuracy')   \n",
    "    plt.plot(val_accs, 'b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runModel(model, batch_size, NUM_OPT_STEPS, optimizer):\n",
    "    train_accs, val_accs = [], []\n",
    "    for i in range(NUM_OPT_STEPS):\n",
    "        train(model, optimizer, batch_size)\n",
    "        if i % 100 == 0:\n",
    "            train_accs.append(approx_train_accuracy(model))\n",
    "            val_accs.append(val_accuracy(model))\n",
    "            print(\"%6d %5.2f %5.2f\" % (i, train_accs[-1], val_accs[-1]))\n",
    "    plot(train_accs, val_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_1 = 32\n",
    "layer_2 = 32\n",
    "layer_3 = 64\n",
    "layer_4 = 64\n",
    "batch = 60\n",
    "rate = 0.001\n",
    "step = 20000\n",
    "model = TooSimpleConvNN(layer_1, layer_2, layer_3, layer_4)\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=rate)\n",
    "runModel(model, batch, step, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
